{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('spam').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1f7c2e5-83b4-483e-8755-9b403d3364e6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["data = spark.read.csv('/FileStore/tables/SMSSPA_1', inferSchema=True, sep='\\t')\ndata.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd5f79f6-1c19-4614-bfdd-2d4fda555649"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+--------------------+\n| _c0|                 _c1|\n+----+--------------------+\n| ham|Go until jurong p...|\n| ham|Ok lar... Joking ...|\n|spam|Free entry in 2 a...|\n| ham|U dun say so earl...|\n| ham|Nah I don't think...|\n+----+--------------------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+--------------------+\n| _c0|                 _c1|\n+----+--------------------+\n| ham|Go until jurong p...|\n| ham|Ok lar... Joking ...|\n|spam|Free entry in 2 a...|\n| ham|U dun say so earl...|\n| ham|Nah I don't think...|\n+----+--------------------+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')\ndata.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec6a0bee-9adb-4584-9d8b-c0aac531b98f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+\n|class|                text|\n+-----+--------------------+\n|  ham|Go until jurong p...|\n|  ham|Ok lar... Joking ...|\n| spam|Free entry in 2 a...|\n|  ham|U dun say so earl...|\n|  ham|Nah I don't think...|\n+-----+--------------------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+\n|class|                text|\n+-----+--------------------+\n|  ham|Go until jurong p...|\n|  ham|Ok lar... Joking ...|\n| spam|Free entry in 2 a...|\n|  ham|U dun say so earl...|\n|  ham|Nah I don't think...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import length\ndata = data.withColumn('length', length(data['text']))\ndata.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f03fda6-0fda-4e5c-a50c-fa0b3716c4b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+------+\n|class|                text|length|\n+-----+--------------------+------+\n|  ham|Go until jurong p...|   111|\n|  ham|Ok lar... Joking ...|    29|\n| spam|Free entry in 2 a...|   155|\n|  ham|U dun say so earl...|    49|\n|  ham|Nah I don't think...|    61|\n+-----+--------------------+------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+------+\n|class|                text|length|\n+-----+--------------------+------+\n|  ham|Go until jurong p...|   111|\n|  ham|Ok lar... Joking ...|    29|\n| spam|Free entry in 2 a...|   155|\n|  ham|U dun say so earl...|    49|\n|  ham|Nah I don't think...|    61|\n+-----+--------------------+------+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["data.groupBy('class').mean().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07264bf9-e7b1-4ee6-9982-973c0a7e7988"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+-----------------+\n|class|      avg(length)|\n+-----+-----------------+\n|  ham| 71.4545266210897|\n| spam|138.6706827309237|\n+-----+-----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+-----------------+\n|class|      avg(length)|\n+-----+-----------------+\n|  ham| 71.4545266210897|\n| spam|138.6706827309237|\n+-----+-----------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer,  StopWordsRemover, CountVectorizer, IDF, StringIndexer\ntokenizer = Tokenizer(inputCol='text', outputCol='token_text')\nstopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_token')\ncount_vec = CountVectorizer(inputCol='stop_token', outputCol='count_vec')\nidf = IDF(inputCol='count_vec', outputCol='tf_idf')\nclass_to_num = StringIndexer(inputCol='class', outputCol='label')\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d537ed81-3085-463f-8164-3c77d85614e0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nclean_up =VectorAssembler(inputCols=['tf_idf', 'length'], outputCol='features')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a44ff367-afdd-43f0-929f-6339f79f2b6e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f37f439a-2047-47f6-917e-963487494d22"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml import Pipeline\ndata_prep_pipe = Pipeline(stages = [class_to_num, tokenizer, stopremove, count_vec , idf, clean_up])\ncleaner = data_prep_pipe.fit(data)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb492e38-6f15-4946-ab8c-66d48cea02d5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["clean_data = cleaner.transform(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"305534ee-e94b-41ed-90fc-4fa003c89766"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["clean_data.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e211ea4-d458-49d4-b167-fde1dd229504"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|class|                text|length|label|          token_text|          stop_token|           count_vec|              tf_idf|            features|\n+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|\n| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|class|                text|length|label|          token_text|          stop_token|           count_vec|              tf_idf|            features|\n+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|\n| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["clean_data = clean_data.select('label','features')\nclean_data.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35f19b81-652d-4f69-8529-8ef60096ba69"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(13424,[7,11,31,6...|\n|  0.0|(13424,[0,24,297,...|\n|  1.0|(13424,[2,13,19,3...|\n|  0.0|(13424,[0,70,80,1...|\n|  0.0|(13424,[36,134,31...|\n+-----+--------------------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(13424,[7,11,31,6...|\n|  0.0|(13424,[0,24,297,...|\n|  1.0|(13424,[2,13,19,3...|\n|  0.0|(13424,[0,70,80,1...|\n|  0.0|(13424,[36,134,31...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["train_data , test_data = clean_data.randomSplit([0.7, 0.3])\nspam_detector = nb.fit(train_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efdc5957-7359-45d4-8163-62b5d4c72538"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["test_results = spam_detector.transform(test_data)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8beb2da3-7c0a-4500-a704-89f05079a27b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nacc_eval = MulticlassClassificationEvaluator()\nacc = acc_eval.evaluate(test_results)\nacc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"337c73ef-006e-48a2-8eb4-049b32b4a7b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[18]: 0.9288872145669496","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[18]: 0.9288872145669496"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01ef7778-8f16-4743-931f-bdea41b8f5b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Spam detection using pyspark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":173559009452810}},"nbformat":4,"nbformat_minor":0}
